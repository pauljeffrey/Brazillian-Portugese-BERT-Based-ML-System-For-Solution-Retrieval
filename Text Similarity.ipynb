{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Similarity.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1B7alaanGs1TeXmU00V6yC8p5SyCLYc1e","authorship_tag":"ABX9TyMEdv9ZhBI/w5IyP4CoOUPN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"F7iN5AQ5BpDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631757151748,"user_tz":-60,"elapsed":8610,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"1ac076c4-06e1-40d9-f3c6-506869779584"},"source":["pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 50.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 42.1 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 43.0 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n"]}]},{"cell_type":"code","metadata":{"id":"t4uwpmcD6GA-"},"source":["import os\n","from transformers import AutoTokenizer  # Or BertTokenizer\n","from transformers import AutoModelForPreTraining , AutoConfig, AutoModel\n","from time import time\n","import huggingface_hub as hb\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import json\n","import pandas as pd\n","import torch\n","import warnings\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Co2bhz6bl-HL"},"source":["warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lmvb0ClIwTp"},"source":["## Introduction\n","The below code changes my working directory to the initialized FILE_PATH. It's a path to a created directory on my google drive where I have stored all the resources and model I need for the code in this notebook to function. To make this work for you, simply create a directory, upload the \n","'Dataset AI.xlsx' excel file into it and edit the FILE_PATH variable to the directory path (of the directory you just created).\n","\n","\n","All the code needed in production have been carefully written and documented in this notebook. It will also be created as a standalone python file for your later use in production.\n"]},{"cell_type":"code","metadata":{"id":"v1rFPBGr6EMa"},"source":["FILE_PATH = '/content/drive/MyDrive/Deep Learning/Text Similarity'\n","os.chdir(FILE_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWfGzwKkJ1_c"},"source":["Now, Let's read the excel file."]},{"cell_type":"markdown","metadata":{"id":"VsOXXT--FVgg"},"source":["The below code is used to download the brazillian \n","portugese bert model to my local directory permanently. To replicate this download, change the FILE_PATH variable specified above to your own local directroy path as explained earlier. Then, the model will be downloaded and be available in your own local directory!\n","\n","Also, uncomment (Remove the '#' and extraspaces on the left side of each line of code) the code to run the code below."]},{"cell_type":"code","metadata":{"id":"kzPw7A_wNM9o"},"source":["# hb.snapshot_download('neuralmind/bert-base-portuguese-cased',cache_dir= FILE_PATH)\n","# for f in os.listdir():\n","#         if f.startswith('neuralmind__bert-base'):\n","#             os.rename(f,'bert-base-portuguese-cased')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jzERShShL1Ys"},"source":["Next, we create a model path to our newly downloaded model."]},{"cell_type":"code","metadata":{"id":"1ky17o3vRpWG"},"source":["model_path = os.path.join(FILE_PATH,'bert-base-portuguese-cased')\n","# The below code forces the model to look offline (in the local directory) for its weight and dependencies.\n","TRANSFORMERS_OFFLINE=1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yNCIYShaMErO"},"source":["Now, we load the model and its tokenizer into memory for computation.\n","The tokenizer is a utility that helps break down the model's input (sentences) into smaller subunits (e.g letters/characters, subwords, words) before it is then passed into the model for downstream processes."]},{"cell_type":"code","metadata":{"id":"MH8nRqssNH8D"},"source":["model = AutoModel.from_pretrained( model_path, local_files_only = True, output_attentions=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5F61ITcUFJq"},"source":["tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True, output_attentions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gTzHGq4BNy5M"},"source":["## Algorithm Creation.\n","Everything here (code and function) has been written according to the flowchart presented earlier. \n","\n","All codes are well commented and explained. The 'query_database' function has been left for your team to create depending on the database management system (sql, oracle etc) that will eventually be used for production.\n","\n","Other functions include:\n","1. load_vectorizer : It loads the BERT model and its tokenizer used for vectorization of defect descriptions.\n","\n","2. vectorize_all_defects: It vectorizes all the defect descriptions.\n","\n","3. get_success_rate: It calculates the success rates of each solution retrieved from the database.\n","\n","4. sort_score: It sorts the calculated similarity score of each vectorized defect description.\n","\n","5. get_solution: This is the powerhouse of the algorithm. Given its required input, its retrieves all relevant solutions, groups into levels: l1, l2, l3 and returns these with the order_id, work_order, order_type (whether customer or technician), success rate of each solution.\n","\n","A python file containing only this cell can be found in the same directory as this notebook."]},{"cell_type":"code","metadata":{"id":"4SZOFEeIklPc"},"source":["def load_vectorizer(model_path=model_path):\n","  ''' This function loads the BERT model to memory for vectorization'''\n","  # Load the BERT model:\n","  model = AutoModel.from_pretrained( model_path, local_files_only = True, output_attentions=True)\n","  # Load the tokenizer:\n","  tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n","\n","  # Return the model and tokenizer:\n","  return model, tokenizer\n","\n","\n","def vectorize_all_defects(all_defects, model,tokenizer,max_length=128, batch_size=1000):\n","  ''' This function vectorizes 'all_defects' in batches (using the provided model and tokenizer arguments) \n","      and concatenates all the resulting embeddings into one tensor (array) container\n","  '''\n","  # First tokenize and vectorize the first batch from 'all_defects'\n","  # Tokenize first batch:\n","  tokens = tokenizer.batch_encode_plus(all_defects,max_length= max_length, padding='max_length',truncation=True,return_tensors='pt')\n","  attention_mask = tokens['attention_mask']\n","\n","  # Vectorize first batch and store result in 'embeddings' variable.\n","  with torch.no_grad():\n","    outs = model(**tokens)\n","    # The vector embeddings are stored in the last_hidden_state of the model so we retrieve it.\n","    embeddings = outs.last_hidden_state \n","\n","  # Make attention mask have exactly the same size and shape as the vectorized embeddings:\n","  # This is done because not all defects have similar sequence length and so they were all padded to the same size.\n","  # Therefore, attention mask here is used to ignore all the paddings.\n","  attention_mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n","  embeddings = embeddings * attention_mask\n","\n","  # summed_embeddings = torch.sum(embeddings, 1)\n","  # summed_mask = torch.clamp(attention_mask.sum(1), min=1e-9)\n","  # The embeddings are done for each words in each defect description. Therefore, calculating the mean of each word embeddings per defect description\n","  # gives a standard embedding (mean) of each defect description.\n","  mean_pooled_embeddings = torch.sum(embeddings, 1) / torch.clamp(attention_mask.sum(1), min=1e-9)\n","\n","  # Now, apply the same process to other batches and continue concatenating to the 'embeddings' variable till there are no defects left:\n","  for i in range(batch_size, len(all_defects), batch_size ):\n","  # Tokenize_batch\n","    tokens = tokenizer.batch_encode_plus(sentences,max_length=max_length, padding='max_length',truncation=True,return_tensors='pt')\n","    attention_mask = tokens['attention_mask']\n","\n","    with torch.no_grad():\n","      outs = model(**tokens)\n","      embeddings = outs.last_hidden_state\n","    \n","    attention_mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n","    embeddings = embeddings * attention_mask\n","    # Calculate the mean of all word embeddings in each defect description:\n","    embeddings = torch.sum(embeddings, 1) / torch.clamp(attention_mask.sum(1), min=1e-9)\n","    # Concatenate this calculated mean_embeddings to the mean_pooled_embeddings:\n","    mean_pooled_embeddings = torch.cat((mean_pooled_embeddings, embeddings),0)\n","\n","  # Return all embeddings:\n","  return mean_pooled_embeddings.detach().numpy() \n","\n","\n","def get_success_rate(solution_id, success_status):\n","  ''' \n","    Function calculates the success_rate (probability) of all solutions retrieved from the database. A more sophisticated function version.\n","    returns : a list of float values that represent the success probability for each solution.\n","  '''\n","  # Get the unique ids:\n","  # Create a dictionary and use each id in unique id as a key:\n","  success_rate_dict = { id : 0 for id in set(solution_id)}\n","  # Create a success rate list to store the probability of success:\n","  success_rate = []\n","\n","  #index = np.arange(len(solution_id))\n","\n","  # Expand dimensions of the solution_id and success_status list objects so we can concatenate them for faster processing:\n","  solution_id = np.expand_dims(solution_id, axis=1)\n","  success_status = np.expand_dims(success_status, axis=1)\n","\n","  # Concatenate them into a 2-dimensional numpy array:\n","  solution_matrix = np.concatenate([solution_id, success_status],axis=-1)\n","\n","  # For each id, filter out all occurences in the list and calculate the probability of success (mean):\n","  # This requires that the success status be represented as '1' for successful and '0' for unsuccessful.\n","  # Success probability is calculated here using the second column (to calculate the mean after filtering the occurences of each id) in the 2-dimensional array:\n","  for id in success_rate_dict.keys():\n","    success_rate_dict[id] = solution_matrix[solution_matrix[:,0] == id][:,1].astype('int').mean()\n","\n","  # Assign the appropriate success probability to the solution id using the success_rate_dict dictionary.\n","  for id in solution_id[:,1]:\n","    success_rate.append(success_rate_dict[id])\n","\n","  # Return success_rate\n","  return success_rate\n","\n","\n","def get_prob_success(solution_id, solution_counter):\n","  ''' \n","    Function calculates the success_rate (probability) of all solutions retrieved from the database. This is the function used by the algorithm\n","    written below this function definition.\n","    returns : a list of float values that represent the success probability for each solution.\n","  '''\n","  # Convert solution_counter to a numpy array:\n","  solution_counter = np.array(solution_counter)\n","  # Calculate the total counts of all solutions:\n","  total_count = solution_counter.sum()\n","  # Calculate and round up success_percentage to 1 decimal place:\n","  success_percentage = np.round((solution_counter / total_count * 100), 1)\n","  \n","  return success_percentage\n"," \n","\n","def query_database(top_defects_ids):\n","  ''' This function queries the database given the ids of the most similar defect descriptions and a condition (whether to return L1 solutions). \n","      It has been specifically left to be created by your team depending on the database management software that is being used.\n","      It should return solution_ids , solution_level , solution_counter. Each of these columns should be a list.\n","      Function should return None, None, None for these columns if no solution was found in the database.'''\n","  pass\n","\n","# Define a sort_score function to sort the similarity scores in descending order.\n","def sort_score(scores):\n","  '''\n","    The function sorts the similarity score in descending order and returns it.\n","  '''\n","  result = []\n","  for each in scores:\n","    result.append(each)\n","  # Sort the list according to the similarity scores:\n","  result.sort(key=lambda x: x[1],reverse=True)\n","  return np.array(result)\n","\n","def get_solution(work_order, all_defect_ids, all_defect_descriptions, tokenizer,\n","                 bert_model, level='customer', threshold_score=0.8, batch_size= 1000, top_k=-1, return_type='json'):\n","  '''This function using deep learning, retrieves and returns the solutions and respective success_rates of the most similar workorder to the work order\n","     or description provided as one of its input. It returns an empty dictionary if no viable solution was found in the database.\n","     Args:\n","      work_order: string, a description of the defect created by a customer/ techinician - customer defect\n","      all_defect_ids: Ids of all defects stored in the database\n","      all_defect_descriptions: Description of all defects stored in the database.\n","      tokenizer: BERT model tokenizer\n","      bert_model: BERT model used as vectorizer by this function.\n","      level: 'customer' or 'technician'. It describes the person who created the work_order\n","      threshold_score: float, default == 0.8. It determines the similarity threshold score to use when retrieving the top_K similar defects.\n","      batch_size : integer , default == 1000, the number of defect descriptions to process/vectorize at once using multiprocessing.\n","      top_k: integer, default == -1. The number of defects to consider after similarity score computation.\n","      return_type: string, default == 'json'. It determines whether the function should return a dictionary or json object.\n","  '''\n","  # Convert list of defect_ids to a numpy array:\n","  all_defect_ids = np.array(all_defect_ids)\n","\n","  ## Pass customer work order/tech_defect_description and all_defect_descriptions to vectorizer: BERT model \n","  # Add the 'work order' to the 'all_defect_descriptions' for computational convenience:\n","  all_defect_descriptions.insert(0, work_order)\n","\n","  # Compute vectorized embeddings:\n","  vectorized_embeddings  = vectorize_all_defects(all_defect_descriptions, bert_model, tokenizer)\n","  \n","  # Calculate the cosine similarity between customer work order and all other descriptions extracted from the database:\n","  similarity_scores = cosine_similarity([vectorized_embeddings[0]], vectorized_embeddings[1:])\n","\n","  # Concatenate defect_ids to vectorized_defect_descriptions:\n","  # First expand the dimensions of both 'all_defect_ids' and 'similarity_scores' to a 2-dimensional array:\n","  all_defects_ids = np.expand_dims(all_defect_ids, 1)\n","  n_samples  = similarity_scores.shape[-1]\n","  # Reshape similarity scores:\n","  similarity_scores = similarity_scores.reshape(n_samples, 1)\n","\n","  # Concatenate both into a single array:\n","  similarity_scores_id = np.concatenate((all_defects_ids, similarity_scores), axis= -1)\n","\n","  # Filter the top k defects greater than threshold score:\n","  top_defects = similarity_scores_id[ similarity_scores_id[:,1] > threshold_score]\n","\n","  # Sort similarity scores:\n","  top_defects  = sort_score(top_defects)\n","\n","  # Extract only the top_k ids for this descriptions with high similarity score:\n","  top_defect_ids  = top_defects[: top_k,0]\n","\n","  # Query database with this ids here and return solution_ids ,  solution_levels, solution's success percentage:\n","  # If its at customer level return all types of solutions:\n","  # query function is to be defined based on the database management system used.\n","  # query function should return (None, None, None ,None) if no solutions were retrieved.\n","\n","  if  level == 'customer':\n","    solution_ids , solution_level , solution_counter = query_database(topic_defect_ids)\n","  else: # Else return only level 2 and 3 solutions:\n","    solution_ids , solution_level , solution_counter = query_database(topic_defect_ids)\n","  \n","  # If there are no solutions ( we know this by checking if the variable solution_ids == None (is empty))\n","  if solution_ids == None:\n","    # Create an empty dictionary and return it as json object.\n","    result = {}\n","  else:\n","    # Calculate the success percentage:\n","    success_percentage = get_prob_success(solution_ids, solution_counter)\n","\n","    # Group by solution level:\n","    # First, define a dictionary for each level solution.\n","    # If its customer order, create a level 1 dictionary alongside:\n","    if type == 'customer':\n","      level_1 = {}\n","\n","    level_2 = {}\n","    level_3 = {}\n","\n","    # Group by solution level into the appropriate level dictionaries as created above:\n","    # Data structure used for each level dictionary: a dict of {solution_ids: success_percentage}\n","    for index, s_level in enumerate(solution_level):\n","      if s_level == 'L1':\n","        # if solution level for this index solution is level 1, then store solution_id and success percentage as key , value pairs in the level_1 dictionary.\n","        level_1[solution_ids[index]] = success_percentage[index]\n","      elif solution_levels == 'L2':\n","        # Else if level 2 , store in the level 2 dictionary.\n","        level_2[solution_ids[index]] = success_percentage[index]\n","      else:\n","        # Else store in the level 3 dictionary.\n","        level_3[solution_ids[index]] = success_percentage[index]\n","\n","    # Result contains :  order_id , order_type (whether technician or customer), work order , +/- level 1 solutions, level 2 solutions, level 3 solutions.\n","    # If a customer solution (L1 solution) is enabled, return level 1 solution alongside. If not, return level 2 and 3 solution only.\n","    if type == 'customer':\n","      result = {'Level 1': level_1, 'Level 2': level_2, 'Level_3': level_3}\n","    else:\n","      result = {'Level 2': level_2, 'Level_3': level_3}\n","\n","  # Return result as dictionary or json object:\n","  if return_type == 'json':\n","    result = json.dumps(result)\n","  \n","  return  result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrH90RGcQ8tv"},"source":["## Algorithm Testing\n","We will test the algorithm with the excel file dataset. For this, we will modify the main function to suit the requirements of the excel file (This is because in production, a database management system will be used instead of an excel file). \n","\n","To test this algorithm, we will make use of the 'Customer defect' column and  pick out selective rows so that the performance of the algorithm can be appreciated.\n","\n","We will make use of row 2, 9, 12 , 17. These values were chosen because of the uniqueness of the defect description."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"U-v0lhDILgI8","executionInfo":{"status":"ok","timestamp":1631762066778,"user_tz":-60,"elapsed":6,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"304815a0-cf5b-49de-f2ad-59a1f918ad29"},"source":["customer_order = pd.read_excel('Customer order.xlsx')\n","customer_order.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>OUTPUT</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>INPUT L1</th>\n","      <th>INPUT L2</th>\n","      <th>Unnamed: 6</th>\n","      <th>Unnamed: 7</th>\n","      <th>Unnamed: 8</th>\n","      <th>Unnamed: 9</th>\n","      <th>Unnamed: 10</th>\n","      <th>Unnamed: 11</th>\n","      <th>Unnamed: 12</th>\n","      <th>Unnamed: 13</th>\n","      <th>Unnamed: 14</th>\n","      <th>OUTPUT.1</th>\n","      <th>INPUT</th>\n","      <th>INPUT.1</th>\n","      <th>Unnamed: 18</th>\n","      <th>Unnamed: 19</th>\n","      <th>Unnamed: 20</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>English</td>\n","      <td>Solution ID</td>\n","      <td>workorder #</td>\n","      <td>Technician name</td>\n","      <td>Customer defect</td>\n","      <td>Customer defect corrected by technician</td>\n","      <td>Executed service</td>\n","      <td>Solution</td>\n","      <td>Root cause</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>Solution Level</td>\n","      <td>Improve equipment</td>\n","      <td>Parts</td>\n","      <td>Asset Name</td>\n","      <td>Solution counter</td>\n","      <td>Modality</td>\n","      <td>Model</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Portuguese</td>\n","      <td>ID</td>\n","      <td>OS_NO</td>\n","      <td>TECNICO</td>\n","      <td>DEFEITO_CLIENTE</td>\n","      <td>DEFEITO_CLIENTE_AJUSTADO</td>\n","      <td>SERVICO_EXECUTADO</td>\n","      <td>SOLUCAO</td>\n","      <td>CAUSA_RAIZ</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>NIVEL_DE_SOLUCAO</td>\n","      <td>MELHORAR_EQUIPAMENTO</td>\n","      <td>PECAS</td>\n","      <td>NOME_DO_ATIVO</td>\n","      <td>CONT_SOLUCOES</td>\n","      <td>MODALIDADE</td>\n","      <td>MODELO</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não aquece</td>\n","      <td>não esquenta</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>HVAC</td>\n","      <td>Brisa 1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não esfria</td>\n","      <td>não esfria</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>HVAC</td>\n","      <td>Coolmax</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ac não esfria nem esquenta</td>\n","      <td>não liga</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>HVAC</td>\n","      <td>Brisa 2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0       OUTPUT   Unnamed: 2  ... Unnamed: 18 Unnamed: 19 Unnamed: 20\n","0     English  Solution ID  workorder #  ...       CODOS     USER_ID     Column1\n","1  Portuguese           ID        OS_NO  ...       CODOS     USER_ID     Column1\n","2         NaN            1          NaN  ...         NaN         NaN         NaN\n","3         NaN            2          NaN  ...         NaN         NaN         NaN\n","4         NaN            3          NaN  ...         NaN         NaN         NaN\n","\n","[5 rows x 21 columns]"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"YUkojslzbbFY"},"source":["Let's make row 0 the name for each columns. Also, we make the natural index (first column without a name) the ID value for the customer_defects."]},{"cell_type":"code","metadata":{"id":"CrUrAqZTUZgG"},"source":["customer_order.columns = customer_order.loc[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"9e-aslxPbPHq","executionInfo":{"status":"ok","timestamp":1631762068706,"user_tz":-60,"elapsed":18,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"2e426816-3c67-465f-81e6-cd8a1fc9ad7b"},"source":["customer_order.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>Solution ID</th>\n","      <th>workorder #</th>\n","      <th>Technician name</th>\n","      <th>Customer defect</th>\n","      <th>Customer defect corrected by technician</th>\n","      <th>Executed service</th>\n","      <th>Solution</th>\n","      <th>Root cause</th>\n","      <th>TAGS</th>\n","      <th>LAST_UPDATED</th>\n","      <th>Solution Level</th>\n","      <th>Improve equipment</th>\n","      <th>Parts</th>\n","      <th>Asset Name</th>\n","      <th>Solution counter</th>\n","      <th>Modality</th>\n","      <th>Model</th>\n","      <th>CODOS</th>\n","      <th>USER_ID</th>\n","      <th>Column1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>English</td>\n","      <td>Solution ID</td>\n","      <td>workorder #</td>\n","      <td>Technician name</td>\n","      <td>Customer defect</td>\n","      <td>Customer defect corrected by technician</td>\n","      <td>Executed service</td>\n","      <td>Solution</td>\n","      <td>Root cause</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>Solution Level</td>\n","      <td>Improve equipment</td>\n","      <td>Parts</td>\n","      <td>Asset Name</td>\n","      <td>Solution counter</td>\n","      <td>Modality</td>\n","      <td>Model</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Portuguese</td>\n","      <td>ID</td>\n","      <td>OS_NO</td>\n","      <td>TECNICO</td>\n","      <td>DEFEITO_CLIENTE</td>\n","      <td>DEFEITO_CLIENTE_AJUSTADO</td>\n","      <td>SERVICO_EXECUTADO</td>\n","      <td>SOLUCAO</td>\n","      <td>CAUSA_RAIZ</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>NIVEL_DE_SOLUCAO</td>\n","      <td>MELHORAR_EQUIPAMENTO</td>\n","      <td>PECAS</td>\n","      <td>NOME_DO_ATIVO</td>\n","      <td>CONT_SOLUCOES</td>\n","      <td>MODALIDADE</td>\n","      <td>MODELO</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não aquece</td>\n","      <td>não esquenta</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>HVAC</td>\n","      <td>Brisa 1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não esfria</td>\n","      <td>não esfria</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>HVAC</td>\n","      <td>Coolmax</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ac não esfria nem esquenta</td>\n","      <td>não liga</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>HVAC</td>\n","      <td>Brisa 2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0     English  Solution ID  workorder #  ...  CODOS  USER_ID  Column1\n","0     English  Solution ID  workorder #  ...  CODOS  USER_ID  Column1\n","1  Portuguese           ID        OS_NO  ...  CODOS  USER_ID  Column1\n","2         NaN            1          NaN  ...    NaN      NaN      NaN\n","3         NaN            2          NaN  ...    NaN      NaN      NaN\n","4         NaN            3          NaN  ...    NaN      NaN      NaN\n","\n","[5 rows x 21 columns]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BFXwPQmdYez","executionInfo":{"status":"ok","timestamp":1631762068707,"user_tz":-60,"elapsed":13,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"2da3ca3d-cfa0-4810-dad2-233914c79a95"},"source":["customer_order.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['English', 'Solution ID', 'workorder #', 'Technician name',\n","       'Customer defect', 'Customer defect corrected by technician',\n","       'Executed service', 'Solution', 'Root cause', 'TAGS', 'LAST_UPDATED',\n","       'Solution Level', 'Improve equipment', 'Parts', 'Asset Name',\n","       'Solution counter', 'Modality', 'Model', 'CODOS', 'USER_ID', 'Column1'],\n","      dtype='object', name=0)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"0sFlV_cFbwuM"},"source":["Let's define a customized version of the algorithm to suit the dataset provided."]},{"cell_type":"code","metadata":{"id":"Dmk1Wc58ek2D"},"source":["def get_solution_test(order_id, work_order, all_defect_ids, all_defect_descriptions,\n","                 tokenizer, bert_model, threshold_score=0.6, batch_size= 1000, top_k=-1):\n","  '''This function using deep learning, retrieves and returns the solutions and respective success_rates of the most similar workorder to the work order\n","     or description provided as one of its input. It returns an empty dictionary if no viable solution was found in the database.\n","     Args:\n","      order_id : integer value, (id) of the new order created by a customer/ technician.\n","      work_order: string, a description of the defect created by a customer/ techinician.\n","      all_defect_ids: Ids of all defects stored in the database\n","      all_defect_descriptions: Description of all defects stored in the database.\n","      tokenizer: BERT model tokenizer\n","      bert_model: BERT model used as vectorizer by this function.\n","      threshold_score: float, default == 0.7. It determines the similarity threshold score to use when retrieving the top_K similar defects.\n","      batch_size : integer , default == 1000, the number of defect descriptions to process/vectorize at once using multiprocessing.\n","      top_k: integer, default == -1. The number of top defects to consider after similarity score computation.\n","  '''\n","  ## Pass customer work order/tech_defect_description and all_defect_descriptions to vectorizer: BERT model \n","  # Add the 'work order' to the 'all_defect_descriptions' for computational convenience:\n","  all_defect_descriptions.insert(0, work_order)\n","\n","  # Compute vectorized embeddings:\n","  vectorized_embeddings  = vectorize_all_defects(all_defect_descriptions, bert_model, tokenizer)\n","  \n","  # Calculate the cosine similarity between customer work order and all other descriptions extracted from the database:\n","  similarity_scores = cosine_similarity([vectorized_embeddings[0]], vectorized_embeddings[1:])\n","\n","  # Concatenate defect_ids to vectorized_defect_descriptions:\n","  # First expand the dimensions of both 'all_defect_ids' and 'similarity_scores' to a 2-dimensional array:\n","  all_defects_ids = np.expand_dims(all_defect_ids, 1)\n","  n_samples  = similarity_scores.shape[-1]\n","  # Reshape similarity scores:\n","  similarity_scores = similarity_scores.reshape(n_samples, 1)\n","\n","  # Concatenate both into a single array:\n","  similarity_scores_id = np.concatenate((all_defects_ids, similarity_scores), axis= -1)\n","\n","  # Filter the top k defects greater than threshold score:\n","  top_defects = similarity_scores_id[ similarity_scores_id[:,1] > threshold_score]\n","\n","  # Sort similarity scores:\n","  top_defects  = sort_score(top_defects)\n","\n","  # Extract only the top_k ids for this descriptions with high similarity score:\n","  top_defect_ids  = top_defects[: top_k,0]\n","\n","  # Query excel file with this ids here and return solution_ids ,  solution's success percentage:\n","  c_order = customer_order.loc[top_defect_ids]\n","  solution_ids , solution_counter = list(c_order['Solution ID']), list(c_order['Solution counter'])\n","\n","  # If there are no solutions/ similar defects ( we know this by checking if the variable solution_ids == None (is empty))\n","  if len(top_defect_ids) == 0:\n","    # Create an empty dictionary and return it as json object.\n","    print('There were no solutions found for this defect in the database')\n","    return\n","  else:\n","    # Calculate the success percentage:\n","    success_percentage = get_prob_success(solution_ids, solution_counter)\n","    c_order['Success percentage (%)'] = success_percentage\n","    c_order = c_order[['Customer defect','Solution ID', 'Solution counter', 'Success percentage (%)']]\n","    return  work_order , c_order"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6YZNXXILgzOi"},"source":["Now, let's extract the customer orders we are going to be using for demonstration alongside their IDs (the natural index). We will also drop these rows from the dataset."]},{"cell_type":"code","metadata":{"id":"D3Yr2cN7M1BU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631762102979,"user_tz":-60,"elapsed":619,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"d6723bb9-5153-4d70-a521-7b3d8914818e"},"source":["# order ID to be extracted:\n","order_id = [2, 9 ,12, 17]\n","# Customer_defect_orders to be extracted.\n","customer_defect_orders = customer_order['Customer defect'].loc[order_id]\n","customer_defect_orders"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2                  AC não aquece\n","9         aquecedor não funciona\n","12    ar condicionado não aquece\n","17          compressor não parte\n","Name: Customer defect, dtype: object"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"ihi77e6mflAH","executionInfo":{"status":"ok","timestamp":1631762106211,"user_tz":-60,"elapsed":507,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"ce6d826a-2b79-480a-8c81-08c28c214f62"},"source":["# Drop these order_ids from the excel file for convenience:\n","rows = [i for i in range(len(customer_order)) if i not in order_id]\n","database = customer_order.loc[rows]\n","database.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>Solution ID</th>\n","      <th>workorder #</th>\n","      <th>Technician name</th>\n","      <th>Customer defect</th>\n","      <th>Customer defect corrected by technician</th>\n","      <th>Executed service</th>\n","      <th>Solution</th>\n","      <th>Root cause</th>\n","      <th>TAGS</th>\n","      <th>LAST_UPDATED</th>\n","      <th>Solution Level</th>\n","      <th>Improve equipment</th>\n","      <th>Parts</th>\n","      <th>Asset Name</th>\n","      <th>Solution counter</th>\n","      <th>Modality</th>\n","      <th>Model</th>\n","      <th>CODOS</th>\n","      <th>USER_ID</th>\n","      <th>Column1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>English</td>\n","      <td>Solution ID</td>\n","      <td>workorder #</td>\n","      <td>Technician name</td>\n","      <td>Customer defect</td>\n","      <td>Customer defect corrected by technician</td>\n","      <td>Executed service</td>\n","      <td>Solution</td>\n","      <td>Root cause</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>Solution Level</td>\n","      <td>Improve equipment</td>\n","      <td>Parts</td>\n","      <td>Asset Name</td>\n","      <td>Solution counter</td>\n","      <td>Modality</td>\n","      <td>Model</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Portuguese</td>\n","      <td>ID</td>\n","      <td>OS_NO</td>\n","      <td>TECNICO</td>\n","      <td>DEFEITO_CLIENTE</td>\n","      <td>DEFEITO_CLIENTE_AJUSTADO</td>\n","      <td>SERVICO_EXECUTADO</td>\n","      <td>SOLUCAO</td>\n","      <td>CAUSA_RAIZ</td>\n","      <td>TAGS</td>\n","      <td>LAST_UPDATED</td>\n","      <td>NIVEL_DE_SOLUCAO</td>\n","      <td>MELHORAR_EQUIPAMENTO</td>\n","      <td>PECAS</td>\n","      <td>NOME_DO_ATIVO</td>\n","      <td>CONT_SOLUCOES</td>\n","      <td>MODALIDADE</td>\n","      <td>MODELO</td>\n","      <td>CODOS</td>\n","      <td>USER_ID</td>\n","      <td>Column1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não esfria</td>\n","      <td>não esfria</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>HVAC</td>\n","      <td>Coolmax</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ac não esfria nem esquenta</td>\n","      <td>não liga</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>HVAC</td>\n","      <td>Brisa 2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>AC não gela</td>\n","      <td>não funciona</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5</td>\n","      <td>HVAC</td>\n","      <td>Brisa 1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0     English  Solution ID  workorder #  ...  CODOS  USER_ID  Column1\n","0     English  Solution ID  workorder #  ...  CODOS  USER_ID  Column1\n","1  Portuguese           ID        OS_NO  ...  CODOS  USER_ID  Column1\n","3         NaN            2          NaN  ...    NaN      NaN      NaN\n","4         NaN            3          NaN  ...    NaN      NaN      NaN\n","5         NaN            4          NaN  ...    NaN      NaN      NaN\n","\n","[5 rows x 21 columns]"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"Zz6SZeRajQMN"},"source":["Now, let's test our algorithm against the first customer order which was at row 2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0qJfVPVjqGF","executionInfo":{"status":"ok","timestamp":1631762111331,"user_tz":-60,"elapsed":517,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"6c8e5f00-a657-4de3-c124-3732afd6eccf"},"source":["order_id[0], customer_defect_orders[2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 'AC não aquece')"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"feEQAnSjtBRX"},"source":["The model must be loaded first before the algorithm is used so it can attend to all queries.\n","\n","Since we have already loaded the model earlier, we just continue with our algorithm test."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"N3gZxuAWjI08","executionInfo":{"status":"ok","timestamp":1631765125364,"user_tz":-60,"elapsed":16646,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"975e68db-39e3-48b6-e122-a6ced57e7375"},"source":["work_order , result = get_solution_test(order_id[0], customer_defect_orders[2], np.array(database.index), \n","                                   list(database['Customer defect']), tokenizer , model, top_k=4)\n","print(f'The customer work order was: {work_order}')\n","result"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The customer work order was: AC não aquece\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Customer defect</th>\n","      <th>Solution ID</th>\n","      <th>Solution counter</th>\n","      <th>Success percentage (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5.0</th>\n","      <td>AC não gela</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>33.3</td>\n","    </tr>\n","    <tr>\n","      <th>6.0</th>\n","      <td>AC não gela nem aquece</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>3.0</th>\n","      <td>AC não esfria</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>13.3</td>\n","    </tr>\n","    <tr>\n","      <th>10.0</th>\n","      <td>aquecedor não liga</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>33.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0            Customer defect  ... Success percentage (%)\n","5.0              AC não gela  ...                   33.3\n","6.0   AC não gela nem aquece  ...                   20.0\n","3.0            AC não esfria  ...                   13.3\n","10.0      aquecedor não liga  ...                   33.3\n","\n","[4 rows x 4 columns]"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"kHozSCUtq9hi"},"source":["To get more similar result, the top_k and threshold arguments can be adjusted to suit your needs. However, I recommended tuning only the threshold_score in production and leaving the top_k as it is. Here, solution level was not returned because that column is empty in the excel file.\n","\n","We repeat the same thing for other selected orders and we also play with the threshold and top_k values."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":96},"id":"ynWNiVXgkE9y","executionInfo":{"status":"ok","timestamp":1631765145409,"user_tz":-60,"elapsed":15777,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"6161eab3-74d1-46de-cd8a-cd09ec1b2808"},"source":["# We use a threshold_score of 0.8 here\n","work_order , result = get_solution_test(order_id[1], customer_defect_orders[9], np.array(database.index), \n","                                   list(database['Customer defect']), tokenizer , model, threshold_score = 0.8)\n","print(f'The customer work order was: {work_order}')\n","result"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The customer work order was: aquecedor não funciona\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Customer defect</th>\n","      <th>Solution ID</th>\n","      <th>Solution counter</th>\n","      <th>Success percentage (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10.0</th>\n","      <td>aquecedor não liga</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>100.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0        Customer defect Solution ID Solution counter  Success percentage (%)\n","10.0  aquecedor não liga           9                5                   100.0"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"NrhRbgIGkGXL","executionInfo":{"status":"ok","timestamp":1631765160816,"user_tz":-60,"elapsed":15426,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"4364a8b7-b48b-40f4-d83b-cb023642f734"},"source":["# We use a top_k value of 5\n","work_order , result = get_solution_test(order_id[2], customer_defect_orders[12], np.array(database.index), \n","                                   list(database['Customer defect']), tokenizer , model, top_k=5)\n","print(f'The customer work order was: {work_order}')\n","result"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The customer work order was: ar condicionado não aquece\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Customer defect</th>\n","      <th>Solution ID</th>\n","      <th>Solution counter</th>\n","      <th>Success percentage (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14.0</th>\n","      <td>ar condicionado não esquenta</td>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>26.3</td>\n","    </tr>\n","    <tr>\n","      <th>15.0</th>\n","      <td>ar condicionado não gela</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>5.3</td>\n","    </tr>\n","    <tr>\n","      <th>13.0</th>\n","      <td>ar condicionado não esfria</td>\n","      <td>12</td>\n","      <td>5</td>\n","      <td>26.3</td>\n","    </tr>\n","    <tr>\n","      <th>6.0</th>\n","      <td>AC não gela nem aquece</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>15.8</td>\n","    </tr>\n","    <tr>\n","      <th>10.0</th>\n","      <td>aquecedor não liga</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>26.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0                  Customer defect  ... Success percentage (%)\n","14.0  ar condicionado não esquenta  ...                   26.3\n","15.0      ar condicionado não gela  ...                    5.3\n","13.0    ar condicionado não esfria  ...                   26.3\n","6.0         AC não gela nem aquece  ...                   15.8\n","10.0            aquecedor não liga  ...                   26.3\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"7WxW1xAOnQes","executionInfo":{"status":"ok","timestamp":1631765175713,"user_tz":-60,"elapsed":14904,"user":{"displayName":"jeffrey otoibhi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11067368294353522262"}},"outputId":"06dd0af4-a0bd-4e67-8bd6-5a844771ebea"},"source":["# We use a threshold_score of 0.75\n","work_order , result = get_solution_test(order_id[2], customer_defect_orders[12], np.array(database.index), \n","                                   list(database['Customer defect']), tokenizer , model, threshold_score= 0.75)\n","print(f'The customer work order was: {work_order}')\n","result"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The customer work order was: ar condicionado não aquece\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Customer defect</th>\n","      <th>Solution ID</th>\n","      <th>Solution counter</th>\n","      <th>Success percentage (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14.0</th>\n","      <td>ar condicionado não esquenta</td>\n","      <td>13</td>\n","      <td>5</td>\n","      <td>20.8</td>\n","    </tr>\n","    <tr>\n","      <th>15.0</th>\n","      <td>ar condicionado não gela</td>\n","      <td>14</td>\n","      <td>1</td>\n","      <td>4.2</td>\n","    </tr>\n","    <tr>\n","      <th>13.0</th>\n","      <td>ar condicionado não esfria</td>\n","      <td>12</td>\n","      <td>5</td>\n","      <td>20.8</td>\n","    </tr>\n","    <tr>\n","      <th>6.0</th>\n","      <td>AC não gela nem aquece</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>12.5</td>\n","    </tr>\n","    <tr>\n","      <th>10.0</th>\n","      <td>aquecedor não liga</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>20.8</td>\n","    </tr>\n","    <tr>\n","      <th>35.0</th>\n","      <td>ventilador não gira</td>\n","      <td>34</td>\n","      <td>5</td>\n","      <td>20.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["0                  Customer defect  ... Success percentage (%)\n","14.0  ar condicionado não esquenta  ...                   20.8\n","15.0      ar condicionado não gela  ...                    4.2\n","13.0    ar condicionado não esfria  ...                   20.8\n","6.0         AC não gela nem aquece  ...                   12.5\n","10.0            aquecedor não liga  ...                   20.8\n","35.0           ventilador não gira  ...                   20.8\n","\n","[6 rows x 4 columns]"]},"metadata":{},"execution_count":79}]}]}